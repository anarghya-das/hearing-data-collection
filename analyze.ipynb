{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import pyxdf\n",
    "import numpy as np\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_points_vector(eeg_timestamps, marker_timestamps):\n",
    "    # Get the insertion indices for each marker timestamp\n",
    "    indices = np.searchsorted(eeg_timestamps, marker_timestamps)\n",
    "\n",
    "    # Preallocate the output array as a copy of indices.\n",
    "    closest_eeg_indices = indices.copy()\n",
    "\n",
    "    # Create a mask for markers where the insertion index equals 0 (marker before first EEG timestamp)\n",
    "    mask_begin = (indices == 0)\n",
    "    # For these, the closest EEG index is 0 (they cannot use a previous value)\n",
    "    closest_eeg_indices[mask_begin] = 0\n",
    "\n",
    "    # Create a mask for markers where the insertion index equals the length of the EEG timestamps\n",
    "    mask_end = (indices == len(eeg_timestamps))\n",
    "    # For these markers, set the closest EEG index to the last index\n",
    "    closest_eeg_indices[mask_end] = len(eeg_timestamps) - 1\n",
    "\n",
    "    # Create a mask for the \"middle\" markers, i.e., not at the very beginning or end\n",
    "    mask_middle = (indices > 0) & (indices < len(eeg_timestamps))\n",
    "\n",
    "    # For markers in the middle, compute the distance to the previous and next EEG timestamps:\n",
    "    prev_times = eeg_timestamps[indices[mask_middle] - 1]\n",
    "    next_times = eeg_timestamps[indices[mask_middle]]\n",
    "    marker_times_middle = marker_timestamps[mask_middle]\n",
    "\n",
    "    # Calculate the differences\n",
    "    diff_prev = marker_times_middle - prev_times\n",
    "    diff_next = next_times - marker_times_middle\n",
    "\n",
    "    # For each marker in the middle, choose the index of the EEG timestamp that is closer:\n",
    "    # If the distance to the previous timestamp is less or equal than the distance to the next,\n",
    "    # then we pick indices[mask_middle]-1; otherwise, we pick indices[mask_middle].\n",
    "    closest_eeg_indices[mask_middle] = np.where(diff_prev <= diff_next,\n",
    "                                                indices[mask_middle] - 1,\n",
    "                                                indices[mask_middle])\n",
    "\n",
    "    return closest_eeg_indices\n",
    "\n",
    "def create_mappings(event_names, prefix):\n",
    "    marker_dict = {p: i for i, p in enumerate(\n",
    "        np.unique(event_names))}\n",
    "    id_binding = {v: k for k, v in marker_dict.items()}\n",
    "    category_mapping = {\n",
    "        p: {k: v for k, v in marker_dict.items() if k.startswith(p)} for p in prefix\n",
    "    }\n",
    "    return marker_dict, id_binding, category_mapping\n",
    "\n",
    "def create_events(time_points, event_mapping, event_names):\n",
    "    label_id_func = np.vectorize(event_mapping.get)\n",
    "    events = np.zeros((len(time_points), 3), dtype=int)\n",
    "    events[:, 0] = time_points\n",
    "    events[:, 2] = label_id_func(event_names)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG Observations\n",
    "Missing EEG: 129059\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = [129059, 617834, 822866, 991031]\n",
    "EXP_ROOT = \"exp_data\"\n",
    "INPUT_ROOT = \"input\"\n",
    "OUTPUT_ROOT = \"output\"\n",
    "sub_id = subs[1]\n",
    "DATA_FILE = os.path.join(\n",
    "    EXP_ROOT, f\"sub-{sub_id}\", f\"sub-{sub_id}_task-hearing_run-001.xdf\")\n",
    "RAW_VIDEO = os.path.join(INPUT_ROOT, f\"{sub_id}.avi\")\n",
    "# DATA_FILE = os.path.join(EXP_ROOT,\"elizabeth.xdf\")\n",
    "data, header = pyxdf.load_xdf(DATA_FILE)\n",
    "print([stream['info']['type'][0] for stream in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_stream = next(\n",
    "    stream for stream in data if stream['info']['type'][0] == 'Markers')\n",
    "# video_stream = next(\n",
    "#     stream for stream in data if stream['info']['type'][0] == 'Video')\n",
    "# ppg_stream = next(\n",
    "#     stream for stream in data if stream['info']['type'][0] == 'PPG')\n",
    "eeg_stream = next(\n",
    "    stream for stream in data if stream['info']['type'][0] == 'EEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_timestamps = marker_stream['time_stamps']\n",
    "marker_data = np.array(marker_stream['time_series']).squeeze()\n",
    "eeg_data = eeg_stream['time_series'] * 1e-6  # convert to volts\n",
    "eeg_timestamps = eeg_stream['time_stamps']\n",
    "eeg_insert_points = closest_points_vector(eeg_timestamps, marker_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings = ['pmt','hlt','let','ast']\n",
    "marker_dict, id_binding, category_mapping = create_mappings(marker_data, bindings)\n",
    "events = create_events(eeg_insert_points, marker_dict, marker_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_labels = ['L1', 'L2', 'L4', 'L5', 'L7', 'L8', 'L9', 'L10',\n",
    "             'R1', 'R2', 'R4', 'R5', 'R7', 'R8', 'R9', 'R10']\n",
    "# ch_labels = ['Fp1', 'Fp2', 'C3', 'C4', 'P7', 'P8', 'O1',\n",
    "#              'O2', 'F7', 'F8', 'F3', 'F4', 'T7', 'T8', 'P3', 'P4']\n",
    "sampling_rate = 125\n",
    "\n",
    "eeg_data = eeg_stream['time_series'].T * 1e-6\n",
    "info = mne.create_info(\n",
    "    ch_names=ch_labels, sfreq=sampling_rate, ch_types='eeg')\n",
    "raw = mne.io.RawArray(eeg_data, info)\n",
    "# raw.filter(l_freq=1, h_freq=None)\n",
    "\n",
    "flalt_voltage = 0.1\n",
    "_, bads = mne.preprocessing.annotate_amplitude(\n",
    "    raw, flat=dict(eeg=flalt_voltage*1e-6))\n",
    "raw.info['bads'] = bads\n",
    "print(f\"Bad channels: {bads}\")\n",
    "# raw.interpolate_bads()\n",
    "annot = mne.annotations_from_events(\n",
    "    events, raw.info['sfreq'], id_binding)\n",
    "raw.set_annotations(annot)\n",
    "\n",
    "# raw.plot_psd(fmax=62)\n",
    "\n",
    "# raw = raw.notch_filter(60)\n",
    "# bandpass = {'low': 1, 'high': 40}\n",
    "# raw = raw.filter(l_freq=bandpass['low'], h_freq=bandpass['high'])\n",
    "# _, bads = mne.preprocessing.annotate_amplitude(raw, flat=dict(eeg=1e-6))\n",
    "# raw.info['bads'] = ['R1', 'R2', 'R4', 'R5', 'R7', 'R8', 'R9', 'R10']\n",
    "# raw.info['bads'] = bads\n",
    "# print(f\"Bad channels: {bads}\")\n",
    "\n",
    "raw.plot(n_channels=16, scalings='auto', bad_color='red')\n",
    "# raw.plot_psd(fmax=62,dB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot the PSD\n",
    "raw.compute_psd(fmin=1, fmax=60).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.get_data().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "# Approximate positions for 8 electrodes per ear\n",
    "ch_pos = {}\n",
    "radius = 0.015  # Radius around the ear (~15 mm)\n",
    "angles = np.linspace(0, 2 * np.pi, 9)[:-1]  # 8 angles (0° to 315°)\n",
    "\n",
    "# Left ear around LPA\n",
    "lpa = np.array([-0.081, -0.010, 0])  # Slightly behind LPA\n",
    "for i, angle in enumerate(angles):\n",
    "    ch_pos[f'L{i+1}'] = [\n",
    "        lpa[0],  # x: fixed at LPA's x\n",
    "        lpa[1] + radius * np.cos(angle),  # y: varies in circle\n",
    "        lpa[2] + radius * np.sin(angle)   # z: varies in circle\n",
    "    ]\n",
    "\n",
    "# Right ear around RPA\n",
    "rpa = np.array([0.081, -0.010, 0])\n",
    "for i, angle in enumerate(angles):\n",
    "    ch_pos[f'R{i+1}'] = [\n",
    "        rpa[0],  # x: fixed at RPA's x\n",
    "        rpa[1] + radius * np.cos(angle),  # y: varies in circle\n",
    "        rpa[2] + radius * np.sin(angle)   # z: varies in circle\n",
    "    ]\n",
    "\n",
    "# Create the montage\n",
    "montage = mne.channels.make_dig_montage(ch_pos=ch_pos, coord_frame='head')\n",
    "\n",
    "# Assign channel names to match the montage\n",
    "raw.rename_channels({raw.ch_names[i]: list(ch_pos.keys())[i] for i in range(16)})\n",
    "\n",
    "# Set the montage\n",
    "raw.set_montage(montage)\n",
    "\n",
    "# Visualize the sensor positions\n",
    "raw.plot_sensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
